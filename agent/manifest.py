"""Manifest module: tracks the full assessment session as a readable markdown file.

Inspired by the snow-utils manifest pattern, this module creates a human-readable
markdown file that records every phase of an assessment session:

    - Connection details (sanitized)
    - User context decisions (scope, PII, freshness SLAs)
    - Discovery summary (schemas, tables, columns found)
    - Assessment results (scores at each level)
    - Triage decisions (accepted failures, fixes requested)
    - Remediation suggestions generated
    - Comparison results (if re-assessment)

The manifest enables:
    - Replay: re-run an assessment with the same context
    - Resume: continue from a partial assessment
    - Share: export the session for another team member to review
    - Audit: trace every decision that influenced the assessment

Storage location: .aird/manifest.md (in the working directory, or ~/.aird/manifests/).
"""

from __future__ import annotations

import os
from datetime import datetime, timezone
from pathlib import Path
from typing import Any


# ---------------------------------------------------------------------------
# Manifest entry types
# ---------------------------------------------------------------------------

_SECTION_MARKERS = {
    "connection": "connection",
    "context": "context",
    "discovery": "discovery",
    "assessment": "assessment",
    "triage": "triage",
    "remediation": "remediation",
    "comparison": "comparison",
}


def _timestamp() -> str:
    return datetime.now(timezone.utc).strftime("%Y-%m-%dT%H:%M:%SZ")


# ---------------------------------------------------------------------------
# Manifest operations
# ---------------------------------------------------------------------------

def get_manifest_path(working_dir: str | None = None) -> Path:
    """Get the manifest file path.

    Prefers .aird/manifest.md in the working directory.
    Falls back to ~/.aird/manifests/manifest.md.
    """
    if working_dir:
        return Path(working_dir) / ".aird" / "manifest.md"

    # Check if .aird exists in cwd
    local = Path.cwd() / ".aird" / "manifest.md"
    if local.parent.exists():
        return local

    return Path.home() / ".aird" / "manifests" / "manifest.md"


def init_manifest(path: Path, connection: str, platform: str) -> None:
    """Initialize a new manifest file for an assessment session."""
    path.parent.mkdir(parents=True, exist_ok=True)

    header = f"""# AI-Ready Data Assessment Manifest

> Generated by the AI-Ready Data Assessment Agent
> Session started: {_timestamp()}

---

"""
    section = _format_section("connection", "COMPLETE", {
        "connection": _sanitize_for_manifest(connection),
        "platform": platform,
        "timestamp": _timestamp(),
    })

    with open(path, "w") as f:
        f.write(header + section)


def append_section(
    path: Path,
    section_type: str,
    status: str,
    data: dict[str, Any],
) -> None:
    """Append a section to the manifest.

    Args:
        path: Path to the manifest file.
        section_type: One of: connection, context, discovery, assessment, triage, remediation, comparison.
        status: One of: IN_PROGRESS, COMPLETE, FAILED.
        data: Key-value pairs to include in the section.
    """
    if not path.exists():
        # Auto-init with a minimal header if the manifest doesn't exist
        path.parent.mkdir(parents=True, exist_ok=True)
        with open(path, "w") as f:
            f.write(f"# AI-Ready Data Assessment Manifest\n\n> Session started: {_timestamp()}\n\n---\n\n")

    section = _format_section(section_type, status, data)

    with open(path, "a") as f:
        f.write(section)


def update_section_status(path: Path, section_type: str, old_status: str, new_status: str) -> None:
    """Update the status of the most recent section of a given type.

    Replaces the first occurrence of the old status marker with the new status.
    """
    if not path.exists():
        return

    content = path.read_text()
    old_marker = f"<!-- START -- aird:{section_type} | status: {old_status}"
    new_marker = f"<!-- START -- aird:{section_type} | status: {new_status}"

    # Find the LAST occurrence (most recent section)
    idx = content.rfind(old_marker)
    if idx >= 0:
        content = content[:idx] + new_marker + content[idx + len(old_marker):]
        path.write_text(content)


def read_manifest(path: Path) -> str | None:
    """Read the manifest content. Returns None if no manifest exists."""
    if not path.exists():
        return None
    return path.read_text()


def get_latest_section(path: Path, section_type: str) -> dict[str, str] | None:
    """Extract the most recent section of a given type from the manifest.

    Returns a dict with 'status' and 'content' keys, or None if not found.
    """
    if not path.exists():
        return None

    content = path.read_text()
    start_marker = f"<!-- START -- aird:{section_type}"
    end_marker = f"<!-- END -- aird:{section_type} -->"

    # Find the last occurrence
    start_idx = content.rfind(start_marker)
    if start_idx < 0:
        return None

    end_idx = content.find(end_marker, start_idx)
    if end_idx < 0:
        # Section is in progress (no end marker yet)
        section_text = content[start_idx:]
    else:
        section_text = content[start_idx:end_idx + len(end_marker)]

    # Extract status from the start marker
    status_start = section_text.find("status: ") + len("status: ")
    status_end = section_text.find(" ", status_start)
    if status_end < 0:
        status_end = section_text.find("|", status_start)
    status = section_text[status_start:status_end].strip()

    return {"status": status, "content": section_text}


def has_in_progress(path: Path) -> str | None:
    """Check if the manifest has any IN_PROGRESS sections.

    Returns the section type if found, None otherwise.
    """
    if not path.exists():
        return None

    content = path.read_text()
    for section_type in _SECTION_MARKERS:
        marker = f"<!-- START -- aird:{section_type} | status: IN_PROGRESS"
        if marker in content:
            return section_type
    return None


# ---------------------------------------------------------------------------
# Formatting helpers
# ---------------------------------------------------------------------------

def _format_section(section_type: str, status: str, data: dict[str, Any]) -> str:
    """Format a manifest section as markdown with HTML comment markers."""
    lines: list[str] = []

    # Section start marker (machine-readable)
    lines.append(f"<!-- START -- aird:{section_type} | status: {status} | timestamp: {_timestamp()} -->")
    lines.append("")

    # Human-readable header
    title = section_type.replace("_", " ").title()
    lines.append(f"## {title}")
    lines.append("")

    # Content
    for key, value in data.items():
        if isinstance(value, dict):
            lines.append(f"**{_format_key(key)}:**")
            lines.append("")
            for k, v in value.items():
                lines.append(f"- {_format_key(k)}: {v}")
            lines.append("")
        elif isinstance(value, list):
            lines.append(f"**{_format_key(key)}:**")
            lines.append("")
            for item in value:
                if isinstance(item, dict):
                    parts = [f"{k}: {v}" for k, v in item.items()]
                    lines.append(f"- {', '.join(parts)}")
                else:
                    lines.append(f"- {item}")
            lines.append("")
        else:
            lines.append(f"**{_format_key(key)}:** {value}")
    lines.append("")

    # Section end marker
    lines.append(f"<!-- END -- aird:{section_type} -->")
    lines.append("")
    lines.append("---")
    lines.append("")

    return "\n".join(lines)


def _format_key(key: str) -> str:
    """Format a snake_case key as Title Case."""
    return key.replace("_", " ").title()


def _sanitize_for_manifest(connection_string: str) -> str:
    """Remove credentials from a connection string for the manifest."""
    from urllib.parse import urlparse, urlunparse
    try:
        parsed = urlparse(connection_string)
        sanitized = parsed._replace(
            netloc=f"***@{parsed.hostname}" if parsed.hostname else parsed.netloc
        )
        return urlunparse(sanitized)
    except Exception:
        return "***"


# ---------------------------------------------------------------------------
# High-level session helpers
# ---------------------------------------------------------------------------

def record_context(path: Path, ctx: Any) -> None:
    """Record user context decisions in the manifest."""
    data: dict[str, Any] = {}

    if ctx.target_level:
        data["target_level"] = ctx.target_level
    if ctx.excluded_schemas:
        data["excluded_schemas"] = ctx.excluded_schemas
    if ctx.excluded_tables:
        data["excluded_tables"] = ctx.excluded_tables
    if ctx.known_pii_columns:
        data["confirmed_pii_columns"] = ctx.known_pii_columns
    if ctx.false_positive_pii:
        data["confirmed_not_pii"] = ctx.false_positive_pii
    if ctx.nullable_by_design:
        data["nullable_by_design"] = ctx.nullable_by_design
    if ctx.table_criticality:
        data["table_criticality"] = ctx.table_criticality
    if ctx.freshness_slas:
        data["freshness_slas"] = {k: f"{v}h" for k, v in ctx.freshness_slas.items()}
    if ctx.accepted_failures:
        data["accepted_failures"] = ctx.accepted_failures

    infra = []
    if ctx.has_dbt:
        infra.append("dbt")
    if ctx.has_catalog:
        infra.append("data catalog")
    if ctx.has_otel:
        infra.append("OpenTelemetry")
    if ctx.has_iceberg:
        infra.append("Iceberg")
    if infra:
        data["infrastructure"] = ", ".join(infra)

    if data:
        append_section(path, "context", "COMPLETE", data)


def record_discovery(path: Path, inventory: Any) -> None:
    """Record discovery results in the manifest."""
    schema_counts: dict[str, int] = {}
    for table in inventory.tables:
        schema_counts[table.schema] = schema_counts.get(table.schema, 0) + 1

    total_columns = sum(len(t.columns) for t in inventory.tables)

    data: dict[str, Any] = {
        "platform": inventory.detected_platform,
        "schemas": len(schema_counts),
        "tables": len(inventory.tables),
        "columns": total_columns,
        "schema_breakdown": schema_counts,
        "available_providers": ", ".join(inventory.available_providers),
    }

    if inventory.unavailable_providers:
        data["unavailable_providers"] = ", ".join(inventory.unavailable_providers)
    if inventory.permissions_gaps:
        data["permissions_gaps"] = inventory.permissions_gaps

    append_section(path, "discovery", "COMPLETE", data)


def record_assessment(path: Path, report: dict[str, Any]) -> None:
    """Record assessment results in the manifest."""
    summary = report.get("summary", {})
    factors = report.get("factors", {})

    data: dict[str, Any] = {
        "assessment_id": report.get("assessment_id", "unknown"),
        "suite": report.get("suite", "unknown"),
        "timestamp": report.get("timestamp", _timestamp()),
    }

    # Scores
    scores: dict[str, str] = {}
    for level in ["L1", "L2", "L3"]:
        s = summary.get(level, {})
        score_pct = f"{s.get('score', 0) * 100:.1f}%"
        scores[level] = f"{score_pct} ({s.get('pass', 0)} pass, {s.get('fail', 0)} fail, {s.get('skip', 0)} skip)"
    data["scores"] = scores

    # Factor scores
    factor_scores: dict[str, str] = {}
    for factor, levels in factors.items():
        parts = []
        for level in ["L1", "L2", "L3"]:
            score = levels.get(level, 0)
            parts.append(f"{level}: {score * 100:.0f}%")
        factor_scores[factor] = ", ".join(parts)
    data["factor_scores"] = factor_scores

    # Not assessed
    not_assessed = report.get("not_assessed", [])
    if not_assessed:
        data["not_assessed"] = [f"{item.get('requirement', 'general')}: {item.get('reason', '')}" for item in not_assessed]

    # Failure count
    tests = report.get("tests", [])
    fail_count = sum(1 for t in tests if any(t.get("result", {}).get(l) == "fail" for l in ["L1", "L2", "L3"]))
    data["total_tests"] = len(tests)
    data["tests_with_failures"] = fail_count

    append_section(path, "assessment", "COMPLETE", data)


def record_comparison(path: Path, diff: dict[str, Any]) -> None:
    """Record a comparison result in the manifest."""
    data: dict[str, Any] = {
        "current_id": diff.get("current_id", ""),
        "previous_id": diff.get("previous_id", ""),
    }

    # Score changes
    score_changes: dict[str, str] = {}
    for level, change in diff.get("score_changes", {}).items():
        delta = change.get("delta", 0)
        direction = change.get("direction", "unchanged")
        delta_str = f"+{delta:.1%}" if delta > 0 else f"{delta:.1%}" if delta < 0 else "unchanged"
        score_changes[level] = f"{change.get('previous', 0):.1%} -> {change.get('current', 0):.1%} ({delta_str})"
    data["score_changes"] = score_changes

    improvements = diff.get("improvements", [])
    regressions = diff.get("regressions", [])
    if improvements:
        data["improvements"] = [f"{i['target']} -- {i['requirement']} now passes {i['level']}" for i in improvements]
    if regressions:
        data["regressions"] = [f"{r['target']} -- {r['requirement']} now fails {r['level']}" for r in regressions]

    data["improvements_count"] = len(improvements)
    data["regressions_count"] = len(regressions)

    append_section(path, "comparison", "COMPLETE", data)
